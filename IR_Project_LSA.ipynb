{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48ba0c30-3b1e-42a5-98ee-982d7901a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e942f31-e467-47f3-a642-76dfff0b74c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded Successfully ✅\n",
      "   Patient_ID  Age  Gender      Condition                 Procedure   Cost  \\\n",
      "0           1   45  Female  Heart Disease               Angioplasty  15000   \n",
      "1           2   60    Male       Diabetes           Insulin Therapy   2000   \n",
      "2           3   32  Female  Fractured Arm          X-Ray and Splint    500   \n",
      "3           4   75    Male         Stroke    CT Scan and Medication  10000   \n",
      "4           5   50  Female         Cancer  Surgery and Chemotherapy  25000   \n",
      "\n",
      "   Length_of_Stay Readmission    Outcome  Satisfaction  \n",
      "0               5          No  Recovered             4  \n",
      "1               3         Yes     Stable             3  \n",
      "2               1          No  Recovered             5  \n",
      "3               7         Yes     Stable             2  \n",
      "4              10          No  Recovered             4  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# STEP 2: Load Dataset\n",
    "# -------------------------------\n",
    "# Replace this with your dataset path\n",
    "df = pd.read_csv('C:/Users/91702/Downloads/archive.zip')\n",
    "print(\"Dataset Loaded Successfully ✅\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a8c7f3-8c83-4630-8d63-0afc239cc4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Combine text data\n",
    "df['combined_text'] = df['Condition'].astype(str) + \" \" + df['Procedure'].astype(str) + \" \" + df['Outcome'].astype(str)\n",
    "\n",
    "# 2️⃣ TF-IDF\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=500)\n",
    "X_tfidf = tfidf.fit_transform(df['combined_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a060326-c63d-4ded-a71f-14fe3210c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3️⃣ Apply LSA (Dimensionality Reduction)\n",
    "lsa = TruncatedSVD(n_components=5, random_state=42)\n",
    "X_lsa = lsa.fit_transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c857760-227d-40e5-a845-0fea4da5fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4️⃣ Clustering using LSA features\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(X_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8779afae-463b-4eb2-ad6c-8da0d300593b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Cluster                                antecedents  \\\n",
      "0         1                        (Allergic Reaction)   \n",
      "1         1                    (Epinephrine Injection)   \n",
      "2         1                                (Recovered)   \n",
      "3         1                        (Allergic Reaction)   \n",
      "4         1                              (Angioplasty)   \n",
      "..      ...                                        ...   \n",
      "43        2        (Stable, Medication and Counseling)   \n",
      "44        2  (Hypertension, Medication and Counseling)   \n",
      "45        2                                   (Stable)   \n",
      "46        2                             (Hypertension)   \n",
      "47        2                (Medication and Counseling)   \n",
      "\n",
      "                                  consequents   support  confidence      lift  \n",
      "0                     (Epinephrine Injection)  0.125954    1.000000  7.939394  \n",
      "1                         (Allergic Reaction)  0.125954    1.000000  7.939394  \n",
      "2                         (Allergic Reaction)  0.125954    0.125954  1.000000  \n",
      "3                                 (Recovered)  0.125954    1.000000  1.000000  \n",
      "4                             (Heart Disease)  0.124046    1.000000  8.061538  \n",
      "..                                        ...       ...         ...       ...  \n",
      "43                             (Hypertension)  0.250000    1.000000  4.000000  \n",
      "44                                   (Stable)  0.250000    1.000000  1.000000  \n",
      "45  (Hypertension, Medication and Counseling)  0.250000    0.250000  1.000000  \n",
      "46        (Stable, Medication and Counseling)  0.250000    1.000000  4.000000  \n",
      "47                     (Stable, Hypertension)  0.250000    1.000000  4.000000  \n",
      "\n",
      "[180 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91702\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mlxtend\\frequent_patterns\\association_rules.py:186: RuntimeWarning: invalid value encountered in divide\n",
      "  cert_metric = np.where(certainty_denom == 0, 0, certainty_num / certainty_denom)\n",
      "C:\\Users\\91702\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mlxtend\\frequent_patterns\\association_rules.py:186: RuntimeWarning: invalid value encountered in divide\n",
      "  cert_metric = np.where(certainty_denom == 0, 0, certainty_num / certainty_denom)\n"
     ]
    }
   ],
   "source": [
    "# 5️⃣ Apriori per cluster\n",
    "all_rules = []\n",
    "for cluster_id in df['Cluster'].unique():\n",
    "    cluster_data = df[df['Cluster'] == cluster_id]\n",
    "    basket = cluster_data[['Condition', 'Procedure', 'Outcome']].astype(str)\n",
    "    transactions = basket.values.tolist()\n",
    "\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    cluster_df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    frequent_itemsets = apriori(cluster_df, min_support=0.1, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
    "    rules['Cluster'] = cluster_id\n",
    "    all_rules.append(rules)\n",
    "\n",
    "final_rules = pd.concat(all_rules)\n",
    "print(final_rules[['Cluster', 'antecedents', 'consequents', 'support', 'confidence', 'lift']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d39441c-16f1-4d62-96e2-51fce7b43d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
